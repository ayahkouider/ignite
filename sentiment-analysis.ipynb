{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setiment analysis\n- Data preprocessing\n- tokenizing\n- model building\n- Training and Evaluation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport neattext.functions as nfx\nimport nltk\nfrom nltk.corpus import twitter_samples\nfrom nltk.tokenize import word_tokenize\nfrom transformers import pipeline\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.metrics import roc_curve, auc\nimport torch \nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:53:52.461311Z","iopub.execute_input":"2024-06-23T13:53:52.462316Z","iopub.status.idle":"2024-06-23T13:54:12.593820Z","shell.execute_reply.started":"2024-06-23T13:53:52.462269Z","shell.execute_reply":"2024-06-23T13:54:12.593006Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-23 13:53:59.748190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-23 13:53:59.748300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-23 13:53:59.903305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install neattext","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:53:33.083664Z","iopub.execute_input":"2024-06-23T13:53:33.084577Z","iopub.status.idle":"2024-06-23T13:53:47.297336Z","shell.execute_reply.started":"2024-06-23T13:53:33.084535Z","shell.execute_reply":"2024-06-23T13:53:47.296221Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting neattext\n  Downloading neattext-0.1.3-py3-none-any.whl.metadata (12 kB)\nDownloading neattext-0.1.3-py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: neattext\nSuccessfully installed neattext-0.1.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data preprocessing\n- loading data using nltk\n- Turning it into a dataframe\n- encoding the labels\n- removing special characters and stopwords\n- spliting the data","metadata":{}},{"cell_type":"code","source":"nltk.download('twitter_samples')\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:12.595671Z","iopub.execute_input":"2024-06-23T13:54:12.596612Z","iopub.status.idle":"2024-06-23T13:54:12.875938Z","shell.execute_reply.started":"2024-06-23T13:54:12.596576Z","shell.execute_reply":"2024-06-23T13:54:12.874965Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package twitter_samples to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package twitter_samples is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"positive=twitter_samples.strings(\"positive_tweets.json\")\nnegative=twitter_samples.strings(\"negative_tweets.json\")\nneutral=twitter_samples.strings(\"tweets.20150430-223406.json\")\n\npos_df=pd.DataFrame({'tweet': positive, 'label': 'positive'})\nneg_df=pd.DataFrame({'tweet': negative, 'label': 'negative'})\nnuet_df=pd.DataFrame({'tweet': neutral, 'label': 'neutral'})\n\ndata=pd.concat([pos_df,neg_df,nuet_df])","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:12.877210Z","iopub.execute_input":"2024-06-23T13:54:12.877518Z","iopub.status.idle":"2024-06-23T13:54:16.139817Z","shell.execute_reply.started":"2024-06-23T13:54:12.877490Z","shell.execute_reply":"2024-06-23T13:54:16.138691Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"labels={'negative': 0, 'neutral': 1, 'positive': 2}\ndata['label']=data['label'].map(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:16.142654Z","iopub.execute_input":"2024-06-23T13:54:16.142982Z","iopub.status.idle":"2024-06-23T13:54:16.159449Z","shell.execute_reply.started":"2024-06-23T13:54:16.142953Z","shell.execute_reply":"2024-06-23T13:54:16.158474Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data['tweet'] = data['tweet'].str.replace(r'@\\w+', '', regex=True)\ndata['tweet'] = data['tweet'].str.replace(r'#\\w+', '', regex=True)\ndata['tweet'] = data['tweet'].str.replace(r'RT', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:16.160695Z","iopub.execute_input":"2024-06-23T13:54:16.161024Z","iopub.status.idle":"2024-06-23T13:54:16.283831Z","shell.execute_reply.started":"2024-06-23T13:54:16.160998Z","shell.execute_reply":"2024-06-23T13:54:16.282408Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data['tweet']=data['tweet'].apply(nfx.remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:16.285202Z","iopub.execute_input":"2024-06-23T13:54:16.285585Z","iopub.status.idle":"2024-06-23T13:54:16.465840Z","shell.execute_reply.started":"2024-06-23T13:54:16.285553Z","shell.execute_reply":"2024-06-23T13:54:16.464649Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data[\"tweet\"],data['label'], test_size=0.3, random_state=22)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:16.467216Z","iopub.execute_input":"2024-06-23T13:54:16.467599Z","iopub.status.idle":"2024-06-23T13:54:16.483145Z","shell.execute_reply.started":"2024-06-23T13:54:16.467564Z","shell.execute_reply":"2024-06-23T13:54:16.481833Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing\n- create a dataframe for train and test sets using train_test_split output.\n- define BERT Tokenzer and create a tokenizing funtion.\n- create a tokenized train and test set.\n- add labels to tokenized datasets.\n- format tokenized datasets to be in tensors.","metadata":{}},{"cell_type":"code","source":"train_data=pd.DataFrame({'tweet':X_train,'label':y_train})\ntest_data=pd.DataFrame({'tweet':X_test,'label':y_test})","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:16.485046Z","iopub.execute_input":"2024-06-23T13:54:16.485556Z","iopub.status.idle":"2024-06-23T13:54:16.496674Z","shell.execute_reply.started":"2024-06-23T13:54:16.485518Z","shell.execute_reply":"2024-06-23T13:54:16.494712Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\ndef tokenize(examples):\n    return tokenizer(examples['tweet'], padding='max_length', truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:16.498567Z","iopub.execute_input":"2024-06-23T13:54:16.499746Z","iopub.status.idle":"2024-06-23T13:54:17.261428Z","shell.execute_reply.started":"2024-06-23T13:54:16.499681Z","shell.execute_reply":"2024-06-23T13:54:17.260672Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d91d2cfc9e946ad9b0e6c76c937c1c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd7986d0aca435c962e68e0082d15d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ae3c2962c824cdb874534933cfdc016"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6d04879e34847908dba02bbbb55b569"}},"metadata":{}}]},{"cell_type":"code","source":"train_df=Dataset.from_pandas(train_data)\ntest_df=Dataset.from_pandas(test_data)\n\ntoken_train=train_df.map(tokenize,batched=True)\ntoken_test =test_df.map(tokenize,batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:17.263890Z","iopub.execute_input":"2024-06-23T13:54:17.264164Z","iopub.status.idle":"2024-06-23T13:54:42.221592Z","shell.execute_reply.started":"2024-06-23T13:54:17.264140Z","shell.execute_reply":"2024-06-23T13:54:42.220703Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b35ad06ebfa46ef84de3df4944e9420"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6eacc6c95734b0fb86354ab08f6a919"}},"metadata":{}}]},{"cell_type":"code","source":"token_train=token_train.add_column('labels',train_df['label'])\ntoken_test=token_test.add_column('labels',test_df['label'])\n\ntoken_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntoken_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:42.222734Z","iopub.execute_input":"2024-06-23T13:54:42.223040Z","iopub.status.idle":"2024-06-23T13:54:42.385525Z","shell.execute_reply.started":"2024-06-23T13:54:42.223013Z","shell.execute_reply":"2024-06-23T13:54:42.384734Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Model building\n- load BERT model for classification.\n- define training arguments using 'TraininArguments()' function.\n- define a function for computing accuracy,precision,recall,and F1 score.\n- define trainer.","metadata":{}},{"cell_type":"code","source":"model=BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)\n\ntraining=TrainingArguments(\n    output_dir='./results',\n    run_name='sentiment',\n    evaluation_strategy=\"epoch\",       \n    learning_rate=2e-5,                \n    per_device_train_batch_size=8,     \n    per_device_eval_batch_size=8,      \n    num_train_epochs=5,                \n    weight_decay=0.01,                 \n)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:42.386607Z","iopub.execute_input":"2024-06-23T13:54:42.387015Z","iopub.status.idle":"2024-06-23T13:54:45.412079Z","shell.execute_reply.started":"2024-06-23T13:54:42.386986Z","shell.execute_reply":"2024-06-23T13:54:45.411142Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7006f810f2d84898846e1acb12272e4e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def metrics(p):\n    pred=np.argmax(p.predictions,axis=1)\n    pres,rec,f1,_=precision_recall_fscore_support(p.label_ids,pred,average='weighted')\n    acc=accuracy_score(p.label_ids,pred)\n    return{\n        'accuracy:':acc,\n        'precision:':pres,\n        'recall:':rec,\n        'f1 score:':f1\n    }\n\ntrainer=Trainer(\n   model=model,\n   args=training,\n   train_dataset=token_train,\n   eval_dataset=token_test,\n   tokenizer=tokenizer,\n   compute_metrics=metrics\n)\n   ","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:45.413209Z","iopub.execute_input":"2024-06-23T13:54:45.413496Z","iopub.status.idle":"2024-06-23T13:54:46.429023Z","shell.execute_reply.started":"2024-06-23T13:54:45.413470Z","shell.execute_reply":"2024-06-23T13:54:46.428203Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training and evaluation\n- the data trained for 5 epoch witha batch size of 8 per device.\n- training time:1 hour and 44 minutes.\n- GPU T4 x2 was used for training.","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T13:54:46.430159Z","iopub.execute_input":"2024-06-23T13:54:46.430489Z","iopub.status.idle":"2024-06-23T15:40:19.075850Z","shell.execute_reply.started":"2024-06-23T13:54:46.430462Z","shell.execute_reply":"2024-06-23T15:40:19.074837Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240623_135516-4k83mt3g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ayah_/huggingface/runs/4k83mt3g' target=\"_blank\">sentiment</a></strong> to <a href='https://wandb.ai/ayah_/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ayah_/huggingface' target=\"_blank\">https://wandb.ai/ayah_/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ayah_/huggingface/runs/4k83mt3g' target=\"_blank\">https://wandb.ai/ayah_/huggingface/runs/4k83mt3g</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6565' max='6565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6565/6565 1:44:41, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy:</th>\n      <th>Precision:</th>\n      <th>Recall:</th>\n      <th>F1 score:</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.012100</td>\n      <td>0.011282</td>\n      <td>0.998222</td>\n      <td>0.998234</td>\n      <td>0.998222</td>\n      <td>0.998224</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.006300</td>\n      <td>0.008720</td>\n      <td>0.998889</td>\n      <td>0.998893</td>\n      <td>0.998889</td>\n      <td>0.998890</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.003900</td>\n      <td>0.010091</td>\n      <td>0.998889</td>\n      <td>0.998893</td>\n      <td>0.998889</td>\n      <td>0.998890</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.002700</td>\n      <td>0.008979</td>\n      <td>0.999111</td>\n      <td>0.999114</td>\n      <td>0.999111</td>\n      <td>0.999112</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>0.009234</td>\n      <td>0.999111</td>\n      <td>0.999114</td>\n      <td>0.999111</td>\n      <td>0.999112</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6565, training_loss=0.008580492531933225, metrics={'train_runtime': 6332.2979, 'train_samples_per_second': 16.582, 'train_steps_per_second': 1.037, 'total_flos': 2.762690886144e+16, 'train_loss': 0.008580492531933225, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"results = trainer.evaluate()\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T15:40:19.078463Z","iopub.execute_input":"2024-06-23T15:40:19.078823Z","iopub.status.idle":"2024-06-23T15:42:56.056974Z","shell.execute_reply.started":"2024-06-23T15:40:19.078788Z","shell.execute_reply":"2024-06-23T15:42:56.056114Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='563' max='563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [563/563 02:36]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.00923437811434269, 'eval_accuracy:': 0.9991111111111111, 'eval_precision:': 0.9991139976368262, 'eval_recall:': 0.9991111111111111, 'eval_f1 score:': 0.9991115377994043, 'eval_runtime': 156.9644, 'eval_samples_per_second': 57.338, 'eval_steps_per_second': 3.587, 'epoch': 5.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}