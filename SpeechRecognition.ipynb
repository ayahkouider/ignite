{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6466866,"sourceType":"datasetVersion","datasetId":3735040}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['PYTHONWARNINGS'] = 'ignore:semaphore_tracker:UserWarning'\nos.environ['OMP_NUM_THREADS'] = '1'\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T11:54:58.435671Z","iopub.execute_input":"2024-07-09T11:54:58.436015Z","iopub.status.idle":"2024-07-09T11:54:58.447262Z","shell.execute_reply.started":"2024-07-09T11:54:58.435976Z","shell.execute_reply":"2024-07-09T11:54:58.446378Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Task 2: Speech recognition ","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom keras.preprocessing.sequence import pad_sequences\nimport pytorch_lightning as pl\nimport torch.nn.functional as F\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T17:49:28.442720Z","iopub.execute_input":"2024-07-10T17:49:28.443075Z","iopub.status.idle":"2024-07-10T17:49:46.637983Z","shell.execute_reply.started":"2024-07-10T17:49:28.443045Z","shell.execute_reply":"2024-07-10T17:49:46.636988Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-10 17:49:34.471180: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-10 17:49:34.471293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-10 17:49:34.600816: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SpeechDataset class:\n- for handling dataset features and labels.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class SpeechDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T17:49:46.639782Z","iopub.execute_input":"2024-07-10T17:49:46.640805Z","iopub.status.idle":"2024-07-10T17:49:46.657903Z","shell.execute_reply.started":"2024-07-10T17:49:46.640767Z","shell.execute_reply":"2024-07-10T17:49:46.656974Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Model building:\n- CNN layer for feature extarction.\n- LSTM network sequence modeling.\n- Fully connected layer for classification.\n- Adam optimizer.\n- CTC loss metric.","metadata":{}},{"cell_type":"code","source":"class SpeechRecognitionModel(pl.LightningModule):\n    def __init__(self,num_classes,num_mfcc,max_frames):\n        super(SpeechRecognitionModel,self).__init__()\n        self.num_classes=num_classes\n        self.cnn=nn.Sequential(\n        nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2,stride=2),\n        nn.BatchNorm2d(32),\n        \n        nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2,stride=2),\n        nn.BatchNorm2d(64),\n        \n        nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2,stride=2),\n        nn.BatchNorm2d(128) )\n        self.lstm=nn.LSTM(128*(num_mfcc//8),128,batch_first=True,bidirectional=True,num_layers=2)\n        self.fc=nn.Linear(256,num_classes)\n        \n    def forward(self,x):\n        x=x.unsqueeze(1)\n        batch_size, _, _,_= x.shape\n        x = self.cnn(x)\n        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, 128 * (num_mfcc // 8))\n        x, _ = self.lstm(x)\n        x = self.fc(x)\n        return F.log_softmax(x, dim=-1)\n    \n    def training_step(self,batch,batch_idx):\n        features, labels = batch\n        outputs = self(features)\n        outputs = outputs.permute(1, 0, 2)  \n        input_lengths = torch.full((outputs.size(1),), outputs.size(0), dtype=torch.long)\n        target_lengths = torch.tensor([len(label) for label in labels])\n        loss = F.ctc_loss(outputs, labels, input_lengths, target_lengths)\n        '''outputs=outputs.view(-1,self.num_classes)\n        labels=labels.view(-1)\n        loss=nn.CrossEntropyLoss()(outputs,labels)'''\n        self.log('train_loss',loss)\n        return loss\n    \n    def validation_step(self,batch,batch_idx):\n        features, labels = batch\n        outputs = self(features)\n        outputs = outputs.permute(1, 0, 2)  \n        input_lengths = torch.full((outputs.size(1),), outputs.size(0), dtype=torch.long)\n        target_lengths = torch.tensor([len(label) for label in labels])\n        loss = F.ctc_loss(outputs, labels, input_lengths, target_lengths)\n        self.log('val_loss',loss)\n        return loss\n    \n    def configure_optimizers(self):\n        return optim.Adam(self.parameters(),lr=1e-3)\n    \n    \n            ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data preprocessing and training\n- loading and prepairing audio files.\n- Extracting MFCC features from audio.\n- Padding sequences and normalizing features.\n- Creating data loaders for batch processing.\n- Initializing the model and training with PyTorch Lightning.","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    wave_path = '/kaggle/input/ljspeech-sr16k-dataset/wavs'\n    metadata_path = '/kaggle/input/ljspeech-sr16k-dataset/metadata.csv'\n    df = pd.read_csv(metadata_path)\n    \n    audio_paths=[]\n    for i in range(len(df)):\n        audios=os.path.join(wave_path,df['file_name'][i])\n        audio_paths.append(audios)\n        \n    mfccs=[]\n    for path in audio_paths:\n        y,sr=librosa.load(path,sr=16000)\n        y=librosa.util.normalize(y)\n        mfcc=librosa.feature.mfcc(y=y,sr=16000,n_mfcc=13,n_fft=2048,hop_length=512)\n        mfcc=np.array(mfcc)\n        mfccs.append(mfcc.T)\n        \n    features=mfccs\n    labels=np.array(df['sentence'])\n    \n    chars = set(''.join(labels))\n    char2idx = {char: idx + 1 for idx, char in enumerate(sorted(chars))}\n    char2idx['<pad>']=0\n    idx2char={idx:char for char,idx in char2idx.items()}\n    \n    labels=[[char2idx[char] for char in sentence] for sentence in labels]\n    max_len=max(len(seq) for seq in labels)\n    labels=pad_sequences(labels,maxlen=max_len,padding='post')\n    \n    max_feature = max(feature.shape[0] for feature in features)\n    features=pad_sequences(features,maxlen=max_feature,padding='post',dtype='float32',truncating='post')\n    features=np.array(features)\n    features=features/np.max(np.abs(features))\n    \n    features=torch.tensor(features,dtype=torch.float32)\n    labels=torch.tensor(labels,dtype=torch.long)\n    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=22)\n    train=SpeechDataset(X_train,y_train)\n    test=SpeechDataset(X_test,y_test)\n    \n    train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True, num_workers=3)\n    test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False, num_workers=3)\n    \n    num_classes=len(char2idx)\n    num_mfcc=features.shape[2]\n    max_frames=features.shape[1]\n\n    model=SpeechRecognitionModel(num_classes=num_classes,num_mfcc=num_mfcc,max_frames=max_frames)\n    trainer= pl.Trainer(max_epochs=10,devices='auto',accelerator='gpu')\n    \n    trainer.fit(model,train_loader,test_loader)\n    \n    print(trainer.callback_metrics)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:18:51.883924Z","iopub.execute_input":"2024-07-10T18:18:51.884320Z","iopub.status.idle":"2024-07-10T18:26:27.243537Z","shell.execute_reply.started":"2024-07-10T18:18:51.884284Z","shell.execute_reply":"2024-07-10T18:26:27.242526Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036243014901496aae4c43f9829cec86"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"{'train_loss': tensor(nan), 'val_loss': tensor(nan)}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Results:\n- despite trying different preprcessing and padding techniques as well as different servers for multiprocessing and different IDE's such as jupyter notebook,google colab and kagle the train and val loss are both NaN.\n- feedback and Advise would be appretiated.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}